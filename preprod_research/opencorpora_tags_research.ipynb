{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac8b208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Using cached pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "Collecting docopt>=0.6\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Using cached pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Using cached DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8838b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7896f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "MORPH = pymorphy2.MorphAnalyzer()\n",
    "LERMONTOVIZATION_EPITHETS = ['безумный', 'неземной', 'неотмирен']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb777cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epithet in LERMONTOVIZATION_EPITHETS:\n",
    "    word_obj = MORPH.parse(epithet)[0]\n",
    "    lexeme = word_obj.lexeme\n",
    "    for form in lexeme:\n",
    "        if form.word=='неотмирный':\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a0d104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parse(word='неотмирный', tag=OpencorporaTag('ADJF,Qual masc,sing,nomn'), normal_form='неотмирный', score=1.0, methods_stack=((DictionaryAnalyzer(), 'мирный', 87, 0), (UnknownPrefixAnalyzer(score_multiplier=0.5), 'т'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'нео')))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e671e90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANIMACY',\n",
       " 'ASPECTS',\n",
       " 'CASES',\n",
       " 'FORMAT',\n",
       " 'GENDERS',\n",
       " 'INVOLVEMENT',\n",
       " 'KNOWN_GRAMMEMES',\n",
       " 'MOODS',\n",
       " 'NUMBERS',\n",
       " 'PARTS_OF_SPEECH',\n",
       " 'PERSONS',\n",
       " 'POS',\n",
       " 'RARE_CASES',\n",
       " 'TENSES',\n",
       " 'TRANSITIVITY',\n",
       " 'VOICES',\n",
       " '_CYR2LAT',\n",
       " '_EXTRA_INCOMPATIBLE',\n",
       " '_GRAMMEME_INCOMPATIBLE',\n",
       " '_GRAMMEME_INDICES',\n",
       " '_LAT2CYR',\n",
       " '_NON_PRODUCTIVE_GRAMMEMES',\n",
       " '_NUMERAL_AGREEMENT_GRAMMEMES',\n",
       " '_POS',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_assert_grammemes_are_known',\n",
       " '_assert_grammemes_initialized',\n",
       " '_cyr',\n",
       " '_cyr_grammemes_cache',\n",
       " '_from_internal_grammeme',\n",
       " '_from_internal_tag',\n",
       " '_grammemes_cache',\n",
       " '_grammemes_tuple',\n",
       " '_init_grammemes',\n",
       " '_is_unknown',\n",
       " '_str',\n",
       " 'add_grammemes_to_known',\n",
       " 'animacy',\n",
       " 'aspect',\n",
       " 'case',\n",
       " 'cyr2lat',\n",
       " 'cyr_repr',\n",
       " 'fix_rare_cases',\n",
       " 'gender',\n",
       " 'grammeme_is_known',\n",
       " 'grammemes',\n",
       " 'grammemes_cyr',\n",
       " 'involvement',\n",
       " 'is_productive',\n",
       " 'lat2cyr',\n",
       " 'mood',\n",
       " 'number',\n",
       " 'numeral_agreement_grammemes',\n",
       " 'person',\n",
       " 'tense',\n",
       " 'transitivity',\n",
       " 'typed_grammemes',\n",
       " 'updated_grammemes',\n",
       " 'voice']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(form.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a5b09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on OpencorporaTag in module pymorphy2.tagset object:\n",
      "\n",
      "class OpencorporaTag(builtins.object)\n",
      " |  OpencorporaTag(tag)\n",
      " |  \n",
      " |  Wrapper class for OpenCorpora.org tags.\n",
      " |  \n",
      " |  .. warning::\n",
      " |  \n",
      " |      In order to work properly, the class has to be globally\n",
      " |      initialized with actual grammemes (using _init_grammemes method).\n",
      " |  \n",
      " |      Pymorphy2 initializes it when loading a dictionary;\n",
      " |      it may be not a good idea to use this class directly.\n",
      " |      If possible, use ``morph_analyzer.TagClass`` instead.\n",
      " |  \n",
      " |  Example::\n",
      " |  \n",
      " |      >>> from pymorphy2 import MorphAnalyzer\n",
      " |      >>> morph = MorphAnalyzer()\n",
      " |      >>> Tag = morph.TagClass  # get an initialzed Tag class\n",
      " |      >>> tag = Tag('VERB,perf,tran plur,impr,excl')\n",
      " |      >>> tag\n",
      " |      OpencorporaTag('VERB,perf,tran plur,impr,excl')\n",
      " |  \n",
      " |  Tag instances have attributes for accessing grammemes::\n",
      " |  \n",
      " |      >>> print(tag.POS)\n",
      " |      VERB\n",
      " |      >>> print(tag.number)\n",
      " |      plur\n",
      " |      >>> print(tag.case)\n",
      " |      None\n",
      " |  \n",
      " |  Available attributes are: POS, animacy, aspect, case, gender, involvement,\n",
      " |  mood, number, person, tense, transitivity and voice.\n",
      " |  \n",
      " |  You may check if a grammeme is in tag or if all grammemes\n",
      " |  from a given set are in tag::\n",
      " |  \n",
      " |      >>> 'perf' in tag\n",
      " |      True\n",
      " |      >>> 'nomn' in tag\n",
      " |      False\n",
      " |      >>> 'Geox' in tag\n",
      " |      False\n",
      " |      >>> set(['VERB', 'perf']) in tag\n",
      " |      True\n",
      " |      >>> set(['VERB', 'perf', 'sing']) in tag\n",
      " |      False\n",
      " |  \n",
      " |  In order to fight typos, for unknown grammemes an exception is raised::\n",
      " |  \n",
      " |      >>> 'foobar' in tag\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: Grammeme is unknown: foobar\n",
      " |      >>> set(['NOUN', 'foo', 'bar']) in tag\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: Grammemes are unknown: {'bar', 'foo'}\n",
      " |  \n",
      " |  This also works for attributes::\n",
      " |  \n",
      " |      >>> tag.POS == 'plur'\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: 'plur' is not a valid grammeme for this attribute. Valid grammemes: ...\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  POS\n",
      " |      Descriptor object for accessing grammemes of certain classes\n",
      " |      (e.g. number or voice).\n",
      " |  \n",
      " |  __contains__(self, grammeme)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, tag)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __reduce__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  animacy\n",
      " |      Descriptor object for accessing grammemes of certain classes\n",
      " |      (e.g. number or voice).\n",
      " |  \n",
      " |  aspect\n",
      " |      Descriptor object for accessing grammemes of certain classes\n",
      " |      (e.g. number or voice).\n",
      " |  \n",
      " |  case\n",
      " |      Descriptor object for accessing grammemes of certain classes\n",
      " |      (e.g. number or voice).\n",
      " |  \n",
      " |  gender\n",
      " |      Descriptor object for accessing grammemes of certain classes\n",
      " |      (e.g. number or voice).\n",
      " |  \n",
      " |  involvement\n",
      " |      Descriptor object for accessing grammemes of certain classes\n",
      " |      (e.g. number or voice).\n",
      " |  \n",
      " |  is_productive(self)\n",
      " |  \n",
      " |  mood\n",
      " |      Descriptor object for accessing grammemes of certain classes\n",
      " |      (e.g. number or voice).\n",
      " |  \n",
      " |  number\n",
      " |      Descriptor object for accessing grammemes of certain classes\n",
      " |      (e.g. number or voice).\n",
      " |  \n",
      " |  numeral_agreement_grammemes(self, num)\n",
      " |  \n",
      " |  person\n",
      " |      Descriptor object for accessing grammemes of certain classes\n",
      " |      (e.g. number or voice).\n",
      " |  \n",
      " |  tense\n",
      " |      Descriptor object for accessing grammemes of certain classes\n",
      " |      (e.g. number or voice).\n",
      " |  \n",
      " |  transitivity\n",
      " |      Descriptor object for accessing grammemes of certain classes\n",
      " |      (e.g. number or voice).\n",
      " |  \n",
      " |  updated_grammemes(self, required)\n",
      " |      Return a new set of grammemes with ``required`` grammemes added\n",
      " |      and incompatible grammemes removed.\n",
      " |  \n",
      " |  voice\n",
      " |      Descriptor object for accessing grammemes of certain classes\n",
      " |      (e.g. number or voice).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  add_grammemes_to_known(lat, cyr, overwrite=True) from builtins.type\n",
      " |  \n",
      " |  cyr2lat(tag_or_grammeme) from builtins.type\n",
      " |      Return Latin representation for ``tag_or_grammeme`` string\n",
      " |  \n",
      " |  fix_rare_cases(grammemes) from builtins.type\n",
      " |      Replace rare cases (loc2/voct/...) with common ones (loct/nomn/...).\n",
      " |  \n",
      " |  grammeme_is_known(grammeme) from builtins.type\n",
      " |  \n",
      " |  lat2cyr(tag_or_grammeme) from builtins.type\n",
      " |      Return Cyrillic representation for ``tag_or_grammeme`` string\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  cyr_repr\n",
      " |      Cyrillic representation of this tag\n",
      " |  \n",
      " |  grammemes\n",
      " |      A frozenset with grammemes for this tag.\n",
      " |  \n",
      " |  grammemes_cyr\n",
      " |      A frozenset with Cyrillic grammemes for this tag.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  ANIMACY = frozenset({'anim', 'inan'})\n",
      " |  \n",
      " |  ASPECTS = frozenset({'impf', 'perf'})\n",
      " |  \n",
      " |  CASES = frozenset({'ablt', 'acc2', 'accs', 'datv', 'gen1', 'gen2', ......\n",
      " |  \n",
      " |  FORMAT = 'opencorpora-int'\n",
      " |  \n",
      " |  GENDERS = frozenset({'femn', 'masc', 'neut'})\n",
      " |  \n",
      " |  INVOLVEMENT = frozenset({'excl', 'incl'})\n",
      " |  \n",
      " |  KNOWN_GRAMMEMES = {'1per', '2per', '3per', 'ADJF', 'ADJS', 'ADVB', ......\n",
      " |  \n",
      " |  MOODS = frozenset({'impr', 'indc'})\n",
      " |  \n",
      " |  NUMBERS = frozenset({'plur', 'sing'})\n",
      " |  \n",
      " |  PARTS_OF_SPEECH = frozenset({'ADJF', 'ADJS', 'ADVB', 'COMP', 'CONJ', '...\n",
      " |  \n",
      " |  PERSONS = frozenset({'1per', '2per', '3per'})\n",
      " |  \n",
      " |  RARE_CASES = {'acc1': 'accs', 'acc2': 'accs', 'gen1': 'gent', 'gen2': ...\n",
      " |  \n",
      " |  TENSES = frozenset({'futr', 'past', 'pres'})\n",
      " |  \n",
      " |  TRANSITIVITY = frozenset({'intr', 'tran'})\n",
      " |  \n",
      " |  VOICES = frozenset({'actv', 'pssv'})\n",
      " |  \n",
      " |  typed_grammemes = True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(form.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5205b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Available attributes are:POS, animacy, aspect, case, gender, involvement,\n",
    "# mood, number, person, tense, transitivity and voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c1b5bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJF\n"
     ]
    }
   ],
   "source": [
    "print(form.tag.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6789cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(form.tag.animacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96ec9a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(form.tag.aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12661656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nomn\n"
     ]
    }
   ],
   "source": [
    "print(form.tag.case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42d901a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masc\n"
     ]
    }
   ],
   "source": [
    "print(form.tag.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a42f0add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(form.tag.involvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b6f8a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(form.tag.mood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb97ddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sing\n"
     ]
    }
   ],
   "source": [
    "print(form.tag.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99b3601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(form.tag.person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c14769e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(form.tag.tense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c108ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(form.tag.transitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29eba861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(form.tag.voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1e12eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpencorporaTag('ADJF,Qual masc,sing,nomn')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "256e1117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Qual' in form.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1eea79a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'masc' in form.tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ceede",
   "metadata": {},
   "source": [
    "С атрибутами тега работать не удобно, т.к. через них доступны не все граммемы, принадлежащие слову. Лучше работать с тегом\n",
    "как со строкой, выделяя подстроки всех граммем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b71d2b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump(obj,):\n",
    "  for attr in dir(obj):\n",
    "    value = getattr(obj, attr)\n",
    "    print(\"obj.%s = %r\" % (attr, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df435532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj.ANIMACY = frozenset({'anim', 'inan'})\n",
      "obj.ASPECTS = frozenset({'perf', 'impf'})\n",
      "obj.CASES = frozenset({'accs', 'gent', 'datv', 'nomn', 'loc1', 'gen1', 'acc2', 'loct', 'ablt', 'loc2', 'voct', 'gen2'})\n",
      "obj.FORMAT = 'opencorpora-int'\n",
      "obj.GENDERS = frozenset({'masc', 'femn', 'neut'})\n",
      "obj.INVOLVEMENT = frozenset({'incl', 'excl'})\n",
      "obj.KNOWN_GRAMMEMES = {'perf', 'V-be', 'V-en', 'NUMR', 'masc', 'ASpc', 'ADVB', 'real', 'Init', 'Inmx', 'Apro', 'gen2', 'ANim', 'pssv', 'VOic', 'Abbr', 'V-ie', 'Infr', 'NOUN', 'COMP', 'anim', 'Dmns', 'Geox', 'PRED', 'Name', 'ADJF', 'neut', 'Refl', 'V-oy', 'nomn', 'PRTF', 'INTJ', 'futr', 'Poss', 'PErs', 'Prdx', 'impr', 'INFN', 'POST', 'past', 'Erro', 'GNdr', 'Slng', 'CAse', 'LATN', 'Fixd', 'PRCL', 'GRND', 'tran', 'ROMN', 'Adjx', 'impf', 'Ms-f', 'Impe', 'Orgn', 'Hypo', 'Coun', 'gent', 'MOod', 'V-bi', 'Patr', 'TRns', 'Surn', 'VERB', 'Litr', 'Coll', 'NMbr', 'ms-f', 'gen1', 'V-sh', 'Prnt', 'Sgtm', 'pres', 'Cmp2', 'incl', 'inan', 'PRTS', '3per', '1per', 'acc2', 'loc1', 'ADJS', 'Mult', 'accs', 'NPRO', 'Anph', 'CONJ', 'NUMB', 'loct', 'ablt', 'indc', 'voct', 'V-ey', 'femn', 'PNCT', 'Subx', 'PREP', '2per', 'Ques', 'Af-p', 'V-ej', 'Trad', 'INvl', 'Anum', 'Pltm', 'intr', 'TEns', 'sing', 'excl', 'Vpre', 'Fimp', 'Dist', 'Impx', 'intg', 'Supr', 'plur', 'Qual', 'loc2', 'actv', 'datv', 'Arch', 'UNKN'}\n",
      "obj.MOODS = frozenset({'indc', 'impr'})\n",
      "obj.NUMBERS = frozenset({'plur', 'sing'})\n",
      "obj.PARTS_OF_SPEECH = frozenset({'NOUN', 'PRTS', 'NPRO', 'COMP', 'PRTF', 'CONJ', 'PRED', 'NUMR', 'GRND', 'ADJF', 'PRCL', 'VERB', 'ADVB', 'PREP', 'INFN', 'INTJ', 'ADJS'})\n",
      "obj.PERSONS = frozenset({'2per', '3per', '1per'})\n",
      "obj.POS = 'ADJF'\n",
      "obj.RARE_CASES = {'gen1': 'gent', 'gen2': 'gent', 'acc1': 'accs', 'acc2': 'accs', 'loc1': 'loct', 'loc2': 'loct', 'voct': 'nomn'}\n",
      "obj.TENSES = frozenset({'futr', 'past', 'pres'})\n",
      "obj.TRANSITIVITY = frozenset({'tran', 'intr'})\n",
      "obj.VOICES = frozenset({'pssv', 'actv'})\n",
      "obj._CYR2LAT = {'ЧР': 'POST', 'СУЩ': 'NOUN', 'ПРИЛ': 'ADJF', 'КР_ПРИЛ': 'ADJS', 'КОМП': 'COMP', 'ГЛ': 'VERB', 'ИНФ': 'INFN', 'ПРИЧ': 'PRTF', 'КР_ПРИЧ': 'PRTS', 'ДЕЕПР': 'GRND', 'ЧИСЛ': 'NUMR', 'Н': 'ADVB', 'МС': 'NPRO', 'ПРЕДК': 'PRED', 'ПР': 'PREP', 'СОЮЗ': 'CONJ', 'ЧАСТ': 'PRCL', 'МЕЖД': 'INTJ', 'Од-неод': 'ANim', 'од': 'anim', 'неод': 'inan', 'хр': 'GNdr', 'мр': 'masc', 'жр': 'femn', 'ср': 'neut', 'мж': 'ms-f', 'Число': 'NMbr', 'ед': 'sing', 'мн': 'plur', 'sg': 'Sgtm', 'pl': 'Pltm', '0': 'Fixd', 'Падеж': 'CAse', 'им': 'nomn', 'рд': 'gent', 'дт': 'datv', 'вн': 'accs', 'тв': 'ablt', 'пр': 'loct', 'зв': 'voct', 'рд1': 'gen1', 'рд2': 'gen2', 'вн2': 'acc2', 'пр1': 'loc1', 'пр2': 'loc2', 'аббр': 'Abbr', 'имя': 'Name', 'фам': 'Surn', 'отч': 'Patr', 'гео': 'Geox', 'орг': 'Orgn', 'tm': 'Trad', 'субст?': 'Subx', 'превосх': 'Supr', 'кач': 'Qual', 'мест-п': 'Apro', 'числ-п': 'Anum', 'притяж': 'Poss', '*ею': 'V-ey', '*ою': 'V-oy', 'сравн2': 'Cmp2', '*ей': 'V-ej', 'Вид': 'ASpc', 'сов': 'perf', 'несов': 'impf', 'Перех': 'TRns', 'перех': 'tran', 'неперех': 'intr', 'безл': 'Impe', 'безл?': 'Impx', 'мног': 'Mult', 'возвр': 'Refl', 'Лицо': 'PErs', '1л': '1per', '2л': '2per', '3л': '3per', 'Время': 'TEns', 'наст': 'pres', 'прош': 'past', 'буд': 'futr', 'Накл': 'MOod', 'изъяв': 'indc', 'повел': 'impr', 'Совм': 'INvl', 'вкл': 'incl', 'выкл': 'excl', 'Залог': 'VOic', 'действ': 'actv', 'страд': 'pssv', 'разг': 'Infr', 'жарг': 'Slng', 'арх': 'Arch', 'лит': 'Litr', 'опеч': 'Erro', 'искаж': 'Dist', 'вопр': 'Ques', 'указ': 'Dmns', 'вводн': 'Prnt', '*ье': 'V-be', '*енен': 'V-en', '*ие': 'V-ie', '*ьи': 'V-bi', '*несов': 'Fimp', 'предк?': 'Prdx', 'счетн': 'Coun', 'собир': 'Coll', '*ши': 'V-sh', '*предл': 'Af-p', 'не/одуш?': 'Inmx', 'в_предл': 'Vpre', 'анаф': 'Anph', 'иниц': 'Init', 'прил?': 'Adjx', 'ор': 'Ms-f', 'гипот': 'Hypo', 'ЧИСЛО': 'NUMB', 'цел': 'intg', 'вещ': 'real', 'ЗПР': 'PNCT', 'РИМ': 'ROMN', 'ЛАТ': 'LATN', 'НЕИЗВ': 'UNKN'}\n",
      "obj._EXTRA_INCOMPATIBLE = {'plur': {'GNdr', 'ms-f', 'masc', 'femn', 'neut'}}\n",
      "obj._GRAMMEME_INCOMPATIBLE = defaultdict(<class 'set'>, {'POST': frozenset(), 'NOUN': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'PRCL', 'VERB', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NPRO', 'COMP', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'ADJF': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'PRCL', 'VERB', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'PRED', 'INFN'}), 'ADJS': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'PRCL', 'VERB', 'ADVB', 'PREP', 'INTJ', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'COMP': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'PRCL', 'VERB', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'VERB': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'PRCL', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'INFN': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'PRCL', 'VERB', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'PRED', 'ADJF'}), 'PRTF': frozenset({'PRTS', 'NUMR', 'GRND', 'PRCL', 'VERB', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'PRTS': frozenset({'PRTF', 'NUMR', 'GRND', 'PRCL', 'VERB', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'GRND': frozenset({'PRTS', 'PRTF', 'NUMR', 'PRCL', 'VERB', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'NUMR': frozenset({'PRTS', 'PRTF', 'PRCL', 'GRND', 'VERB', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'ADVB': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'PRCL', 'VERB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'NPRO': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'PRCL', 'VERB', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'COMP', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'PRED': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'PRCL', 'VERB', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'ADJF', 'INFN'}), 'PREP': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'PRCL', 'VERB', 'ADVB', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'CONJ': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'PRCL', 'VERB', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'PRED', 'ADJF', 'INFN'}), 'PRCL': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'VERB', 'ADVB', 'PREP', 'INTJ', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'INTJ': frozenset({'PRTS', 'PRTF', 'NUMR', 'GRND', 'PRCL', 'VERB', 'ADVB', 'PREP', 'ADJS', 'NOUN', 'NPRO', 'COMP', 'CONJ', 'PRED', 'ADJF', 'INFN'}), 'ANim': frozenset(), 'anim': frozenset({'inan'}), 'inan': frozenset({'anim'}), 'GNdr': frozenset(), 'masc': frozenset({'femn'}), 'femn': frozenset({'masc'}), 'neut': frozenset({'masc', 'ms-f', 'femn'}), 'ms-f': frozenset({'masc', 'femn', 'neut'}), 'NMbr': frozenset(), 'sing': frozenset({'plur'}), 'plur': frozenset({'sing', 'masc', 'GNdr', 'ms-f', 'femn', 'neut'}), 'Sgtm': frozenset(), 'Pltm': frozenset(), 'Fixd': frozenset(), 'CAse': frozenset(), 'nomn': frozenset({'accs', 'gent', 'datv', 'gen1', 'acc2', 'loct', 'ablt', 'voct', 'loc2', 'loc1', 'gen2'}), 'gent': frozenset({'accs', 'datv', 'nomn', 'gen1', 'acc2', 'loct', 'ablt', 'voct', 'loc2', 'loc1', 'gen2'}), 'datv': frozenset({'accs', 'gent', 'nomn', 'gen1', 'acc2', 'loct', 'ablt', 'voct', 'loc2', 'loc1', 'gen2'}), 'accs': frozenset({'gent', 'datv', 'nomn', 'gen1', 'acc2', 'loct', 'ablt', 'voct', 'loc2', 'loc1', 'gen2'}), 'ablt': frozenset({'accs', 'gent', 'datv', 'nomn', 'gen1', 'acc2', 'loct', 'voct', 'loc2', 'loc1', 'gen2'}), 'loct': frozenset({'accs', 'gent', 'datv', 'nomn', 'gen1', 'acc2', 'ablt', 'voct', 'loc2', 'loc1', 'gen2'}), 'voct': frozenset(), 'gen1': frozenset({'gen2'}), 'gen2': frozenset({'gen1'}), 'acc2': frozenset(), 'loc1': frozenset({'loc2'}), 'loc2': frozenset({'loc1'}), 'Abbr': frozenset(), 'Name': frozenset(), 'Surn': frozenset(), 'Patr': frozenset(), 'Geox': frozenset(), 'Orgn': frozenset(), 'Trad': frozenset(), 'Subx': frozenset(), 'Supr': frozenset(), 'Qual': frozenset(), 'Apro': frozenset(), 'Anum': frozenset(), 'Poss': frozenset(), 'V-ey': frozenset(), 'V-oy': frozenset(), 'Cmp2': frozenset(), 'V-ej': frozenset(), 'ASpc': frozenset(), 'perf': frozenset({'impf'}), 'impf': frozenset({'perf'}), 'TRns': frozenset(), 'tran': frozenset({'intr'}), 'intr': frozenset({'tran'}), 'Impe': frozenset(), 'Impx': frozenset(), 'Mult': frozenset(), 'Refl': frozenset(), 'PErs': frozenset(), '1per': frozenset({'2per', '3per'}), '2per': frozenset({'3per', '1per'}), '3per': frozenset({'2per', '1per'}), 'TEns': frozenset(), 'pres': frozenset({'futr', 'past'}), 'past': frozenset({'futr', 'pres'}), 'futr': frozenset({'past', 'pres'}), 'MOod': frozenset(), 'indc': frozenset({'impr'}), 'impr': frozenset({'indc'}), 'INvl': frozenset(), 'incl': frozenset({'excl'}), 'excl': frozenset({'incl'}), 'VOic': frozenset(), 'actv': frozenset({'pssv'}), 'pssv': frozenset({'actv'}), 'Infr': frozenset(), 'Slng': frozenset(), 'Arch': frozenset(), 'Litr': frozenset(), 'Erro': frozenset(), 'Dist': frozenset(), 'Ques': frozenset(), 'Dmns': frozenset(), 'Prnt': frozenset(), 'V-be': frozenset(), 'V-en': frozenset(), 'V-ie': frozenset(), 'V-bi': frozenset(), 'Fimp': frozenset(), 'Prdx': frozenset(), 'Coun': frozenset(), 'Coll': frozenset(), 'V-sh': frozenset(), 'Af-p': frozenset(), 'Inmx': frozenset(), 'Vpre': frozenset(), 'Anph': frozenset(), 'Init': frozenset(), 'Adjx': frozenset(), 'Ms-f': frozenset(), 'Hypo': frozenset()})\n",
      "obj._GRAMMEME_INDICES = defaultdict(<class 'int'>, {'POST': 0, 'NOUN': 1, 'ADJF': 2, 'ADJS': 3, 'COMP': 4, 'VERB': 5, 'INFN': 6, 'PRTF': 7, 'PRTS': 8, 'GRND': 9, 'NUMR': 10, 'ADVB': 11, 'NPRO': 12, 'PRED': 13, 'PREP': 14, 'CONJ': 15, 'PRCL': 16, 'INTJ': 17, 'ANim': 18, 'anim': 19, 'inan': 20, 'GNdr': 21, 'masc': 22, 'femn': 23, 'neut': 24, 'ms-f': 25, 'NMbr': 26, 'sing': 27, 'plur': 28, 'Sgtm': 29, 'Pltm': 30, 'Fixd': 31, 'CAse': 32, 'nomn': 33, 'gent': 34, 'datv': 35, 'accs': 36, 'ablt': 37, 'loct': 38, 'voct': 39, 'gen1': 40, 'gen2': 41, 'acc2': 42, 'loc1': 43, 'loc2': 44, 'Abbr': 45, 'Name': 46, 'Surn': 47, 'Patr': 48, 'Geox': 49, 'Orgn': 50, 'Trad': 51, 'Subx': 52, 'Supr': 53, 'Qual': 54, 'Apro': 55, 'Anum': 56, 'Poss': 57, 'V-ey': 58, 'V-oy': 59, 'Cmp2': 60, 'V-ej': 61, 'ASpc': 62, 'perf': 63, 'impf': 64, 'TRns': 65, 'tran': 66, 'intr': 67, 'Impe': 68, 'Impx': 69, 'Mult': 70, 'Refl': 71, 'PErs': 72, '1per': 73, '2per': 74, '3per': 75, 'TEns': 76, 'pres': 77, 'past': 78, 'futr': 79, 'MOod': 80, 'indc': 81, 'impr': 82, 'INvl': 83, 'incl': 84, 'excl': 85, 'VOic': 86, 'actv': 87, 'pssv': 88, 'Infr': 89, 'Slng': 90, 'Arch': 91, 'Litr': 92, 'Erro': 93, 'Dist': 94, 'Ques': 95, 'Dmns': 96, 'Prnt': 97, 'V-be': 98, 'V-en': 99, 'V-ie': 100, 'V-bi': 101, 'Fimp': 102, 'Prdx': 103, 'Coun': 104, 'Coll': 105, 'V-sh': 106, 'Af-p': 107, 'Inmx': 108, 'Vpre': 109, 'Anph': 110, 'Init': 111, 'Adjx': 112, 'Ms-f': 113, 'Hypo': 114})\n",
      "obj._LAT2CYR = {'POST': 'ЧР', 'NOUN': 'СУЩ', 'ADJF': 'ПРИЛ', 'ADJS': 'КР_ПРИЛ', 'COMP': 'КОМП', 'VERB': 'ГЛ', 'INFN': 'ИНФ', 'PRTF': 'ПРИЧ', 'PRTS': 'КР_ПРИЧ', 'GRND': 'ДЕЕПР', 'NUMR': 'ЧИСЛ', 'ADVB': 'Н', 'NPRO': 'МС', 'PRED': 'ПРЕДК', 'PREP': 'ПР', 'CONJ': 'СОЮЗ', 'PRCL': 'ЧАСТ', 'INTJ': 'МЕЖД', 'ANim': 'Од-неод', 'anim': 'од', 'inan': 'неод', 'GNdr': 'хр', 'masc': 'мр', 'femn': 'жр', 'neut': 'ср', 'ms-f': 'мж', 'NMbr': 'Число', 'sing': 'ед', 'plur': 'мн', 'Sgtm': 'sg', 'Pltm': 'pl', 'Fixd': '0', 'CAse': 'Падеж', 'nomn': 'им', 'gent': 'рд', 'datv': 'дт', 'accs': 'вн', 'ablt': 'тв', 'loct': 'пр', 'voct': 'зв', 'gen1': 'рд1', 'gen2': 'рд2', 'acc2': 'вн2', 'loc1': 'пр1', 'loc2': 'пр2', 'Abbr': 'аббр', 'Name': 'имя', 'Surn': 'фам', 'Patr': 'отч', 'Geox': 'гео', 'Orgn': 'орг', 'Trad': 'tm', 'Subx': 'субст?', 'Supr': 'превосх', 'Qual': 'кач', 'Apro': 'мест-п', 'Anum': 'числ-п', 'Poss': 'притяж', 'V-ey': '*ею', 'V-oy': '*ою', 'Cmp2': 'сравн2', 'V-ej': '*ей', 'ASpc': 'Вид', 'perf': 'сов', 'impf': 'несов', 'TRns': 'Перех', 'tran': 'перех', 'intr': 'неперех', 'Impe': 'безл', 'Impx': 'безл?', 'Mult': 'мног', 'Refl': 'возвр', 'PErs': 'Лицо', '1per': '1л', '2per': '2л', '3per': '3л', 'TEns': 'Время', 'pres': 'наст', 'past': 'прош', 'futr': 'буд', 'MOod': 'Накл', 'indc': 'изъяв', 'impr': 'повел', 'INvl': 'Совм', 'incl': 'вкл', 'excl': 'выкл', 'VOic': 'Залог', 'actv': 'действ', 'pssv': 'страд', 'Infr': 'разг', 'Slng': 'жарг', 'Arch': 'арх', 'Litr': 'лит', 'Erro': 'опеч', 'Dist': 'искаж', 'Ques': 'вопр', 'Dmns': 'указ', 'Prnt': 'вводн', 'V-be': '*ье', 'V-en': '*енен', 'V-ie': '*ие', 'V-bi': '*ьи', 'Fimp': '*несов', 'Prdx': 'предк?', 'Coun': 'счетн', 'Coll': 'собир', 'V-sh': '*ши', 'Af-p': '*предл', 'Inmx': 'не/одуш?', 'Vpre': 'в_предл', 'Anph': 'анаф', 'Init': 'иниц', 'Adjx': 'прил?', 'Ms-f': 'ор', 'Hypo': 'гипот', 'NUMB': 'ЧИСЛО', 'intg': 'цел', 'real': 'вещ', 'PNCT': 'ЗПР', 'ROMN': 'РИМ', 'LATN': 'ЛАТ', 'UNKN': 'НЕИЗВ'}\n",
      "obj._NON_PRODUCTIVE_GRAMMEMES = {'NPRO', 'Apro', 'CONJ', 'PRED', 'NUMR', 'PRCL', 'PREP', 'INTJ'}\n",
      "obj._NUMERAL_AGREEMENT_GRAMMEMES = ({'nomn', 'sing'}, {'accs', 'sing'}, {'gent', 'sing'}, {'nomn', 'plur'}, {'gent', 'plur'})\n",
      "obj._POS = 'ADJF'\n",
      "obj.__class__ = <class 'pymorphy2.tagset.OpencorporaTag'>\n",
      "obj.__contains__ = <bound method OpencorporaTag.__contains__ of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.__delattr__ = <method-wrapper '__delattr__' of OpencorporaTag object at 0x0000009B29559900>\n",
      "obj.__dir__ = <built-in method __dir__ of OpencorporaTag object at 0x0000009B29559900>\n",
      "obj.__doc__ = \"\\n    Wrapper class for OpenCorpora.org tags.\\n\\n    .. warning::\\n\\n        In order to work properly, the class has to be globally\\n        initialized with actual grammemes (using _init_grammemes method).\\n\\n        Pymorphy2 initializes it when loading a dictionary;\\n        it may be not a good idea to use this class directly.\\n        If possible, use ``morph_analyzer.TagClass`` instead.\\n\\n    Example::\\n\\n        >>> from pymorphy2 import MorphAnalyzer\\n        >>> morph = MorphAnalyzer()\\n        >>> Tag = morph.TagClass  # get an initialzed Tag class\\n        >>> tag = Tag('VERB,perf,tran plur,impr,excl')\\n        >>> tag\\n        OpencorporaTag('VERB,perf,tran plur,impr,excl')\\n\\n    Tag instances have attributes for accessing grammemes::\\n\\n        >>> print(tag.POS)\\n        VERB\\n        >>> print(tag.number)\\n        plur\\n        >>> print(tag.case)\\n        None\\n\\n    Available attributes are: POS, animacy, aspect, case, gender, involvement,\\n    mood, number, person, tense, transitivity and voice.\\n\\n    You may check if a grammeme is in tag or if all grammemes\\n    from a given set are in tag::\\n\\n        >>> 'perf' in tag\\n        True\\n        >>> 'nomn' in tag\\n        False\\n        >>> 'Geox' in tag\\n        False\\n        >>> set(['VERB', 'perf']) in tag\\n        True\\n        >>> set(['VERB', 'perf', 'sing']) in tag\\n        False\\n\\n    In order to fight typos, for unknown grammemes an exception is raised::\\n\\n        >>> 'foobar' in tag\\n        Traceback (most recent call last):\\n        ...\\n        ValueError: Grammeme is unknown: foobar\\n        >>> set(['NOUN', 'foo', 'bar']) in tag\\n        Traceback (most recent call last):\\n        ...\\n        ValueError: Grammemes are unknown: {'bar', 'foo'}\\n\\n    This also works for attributes::\\n\\n        >>> tag.POS == 'plur'\\n        Traceback (most recent call last):\\n        ...\\n        ValueError: 'plur' is not a valid grammeme for this attribute. Valid grammemes: ...\\n\\n    \"\n",
      "obj.__eq__ = <bound method OpencorporaTag.__eq__ of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.__format__ = <built-in method __format__ of OpencorporaTag object at 0x0000009B29559900>\n",
      "obj.__ge__ = <method-wrapper '__ge__' of OpencorporaTag object at 0x0000009B29559900>\n",
      "obj.__getattribute__ = <method-wrapper '__getattribute__' of OpencorporaTag object at 0x0000009B29559900>\n",
      "obj.__gt__ = <bound method OpencorporaTag.__gt__ of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.__hash__ = <bound method OpencorporaTag.__hash__ of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.__init__ = <bound method OpencorporaTag.__init__ of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.__init_subclass__ = <built-in method __init_subclass__ of type object at 0x0000009B243A5720>\n",
      "obj.__le__ = <method-wrapper '__le__' of OpencorporaTag object at 0x0000009B29559900>\n",
      "obj.__len__ = <bound method OpencorporaTag.__len__ of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.__lt__ = <bound method OpencorporaTag.__lt__ of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.__module__ = 'pymorphy2.tagset'\n",
      "obj.__ne__ = <bound method OpencorporaTag.__ne__ of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.__new__ = <built-in method __new__ of type object at 0x00007FFEA74BBB50>\n",
      "obj.__reduce__ = <bound method OpencorporaTag.__reduce__ of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.__reduce_ex__ = <built-in method __reduce_ex__ of OpencorporaTag object at 0x0000009B29559900>\n",
      "obj.__repr__ = <bound method OpencorporaTag.__repr__ of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.__setattr__ = <method-wrapper '__setattr__' of OpencorporaTag object at 0x0000009B29559900>\n",
      "obj.__sizeof__ = <built-in method __sizeof__ of OpencorporaTag object at 0x0000009B29559900>\n",
      "obj.__slots__ = ['_grammemes_tuple', '_grammemes_cache', '_str', '_POS', '_cyr', '_cyr_grammemes_cache']\n",
      "obj.__str__ = <bound method OpencorporaTag.__str__ of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.__subclasshook__ = <built-in method __subclasshook__ of type object at 0x0000009B243A5720>\n",
      "obj._assert_grammemes_are_known = <bound method OpencorporaTag._assert_grammemes_are_known of <class 'pymorphy2.tagset.OpencorporaTag'>>\n",
      "obj._assert_grammemes_initialized = <bound method OpencorporaTag._assert_grammemes_initialized of <class 'pymorphy2.tagset.OpencorporaTag'>>\n",
      "obj._cyr = 'ПРИЛ,кач мр,ед,им'\n",
      "obj._cyr_grammemes_cache = frozenset({'мр', 'ед', 'ПРИЛ', 'им', 'кач'})\n",
      "obj._from_internal_grammeme = <bound method OpencorporaTag._from_internal_grammeme of <class 'pymorphy2.tagset.OpencorporaTag'>>\n",
      "obj._from_internal_tag = <bound method OpencorporaTag._from_internal_tag of <class 'pymorphy2.tagset.OpencorporaTag'>>\n",
      "obj._grammemes_cache = frozenset({'nomn', 'masc', 'ADJF', 'Qual', 'sing'})\n",
      "obj._grammemes_tuple = ('ADJF', 'Qual', 'masc', 'sing', 'nomn')\n",
      "obj._init_grammemes = <bound method OpencorporaTag._init_grammemes of <class 'pymorphy2.tagset.OpencorporaTag'>>\n",
      "obj._is_unknown = <bound method OpencorporaTag._is_unknown of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj._str = 'ADJF,Qual masc,sing,nomn'\n",
      "obj.add_grammemes_to_known = <bound method OpencorporaTag.add_grammemes_to_known of <class 'pymorphy2.tagset.OpencorporaTag'>>\n",
      "obj.animacy = None\n",
      "obj.aspect = None\n",
      "obj.case = 'nomn'\n",
      "obj.cyr2lat = <bound method OpencorporaTag.cyr2lat of <class 'pymorphy2.tagset.OpencorporaTag'>>\n",
      "obj.cyr_repr = 'ПРИЛ,кач мр,ед,им'\n",
      "obj.fix_rare_cases = <bound method OpencorporaTag.fix_rare_cases of <class 'pymorphy2.tagset.OpencorporaTag'>>\n",
      "obj.gender = 'masc'\n",
      "obj.grammeme_is_known = <bound method OpencorporaTag.grammeme_is_known of <class 'pymorphy2.tagset.OpencorporaTag'>>\n",
      "obj.grammemes = frozenset({'nomn', 'masc', 'ADJF', 'Qual', 'sing'})\n",
      "obj.grammemes_cyr = frozenset({'мр', 'ед', 'ПРИЛ', 'им', 'кач'})\n",
      "obj.involvement = None\n",
      "obj.is_productive = <bound method OpencorporaTag.is_productive of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.lat2cyr = <bound method OpencorporaTag.lat2cyr of <class 'pymorphy2.tagset.OpencorporaTag'>>\n",
      "obj.mood = None\n",
      "obj.number = 'sing'\n",
      "obj.numeral_agreement_grammemes = <bound method OpencorporaTag.numeral_agreement_grammemes of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.person = None\n",
      "obj.tense = None\n",
      "obj.transitivity = None\n",
      "obj.typed_grammemes = True\n",
      "obj.updated_grammemes = <bound method OpencorporaTag.updated_grammemes of OpencorporaTag('ADJF,Qual masc,sing,nomn')>\n",
      "obj.voice = None\n"
     ]
    }
   ],
   "source": [
    "dump(form.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d77ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj._LAT2CYR\n",
    "obj._CYR2LAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a85a13f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cyr2lat() missing 1 required positional argument: 'tag_or_grammeme'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-57-c286e2bd2892>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mform\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtag\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcyr2lat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m: cyr2lat() missing 1 required positional argument: 'tag_or_grammeme'"
     ]
    }
   ],
   "source": [
    "form.tag.cyr2lat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0636f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'anim', 'inan'})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form.tag.ANIMACY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d46b51c",
   "metadata": {},
   "source": [
    "## Выяснил, что\n",
    "у прилагательных встречаются следующие граммемы, не влияющие на форму слова:\n",
    "*'Qual', 'Subx', 'anim', 'inan'* - качественность, возможность субстантивации, одушевлённость и неодушевлённость.\n",
    "\n",
    "#### при этом\n",
    "Субстантивация может влиять на то, каким членом предложения будет слова (например, \"Больной закрыл дверь\"). Поэтому можно включить пропуск прилогательных, которые могут играть роль существительных, при лермонтовизации текста."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ae5e8",
   "metadata": {},
   "source": [
    "Теперь нужно проверить работу метода .inflect()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ecd36",
   "metadata": {},
   "source": [
    "![alt text](comp_qual_and_comp.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b4c1c",
   "metadata": {},
   "source": [
    "На этом фрагменте таблицы всех встречающихся тегов граммем эпитов лермонтовизации видно, что некторые из них отличаются лишь\n",
    "наличием признака не влияющего на форму слова. Нужно убедиться в том, что присутствие или отсутствие этих признаков в лексеме\n",
    "слова не помешает нам получить его нужную форму через inflect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcd171ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse(word='неотмирный', tag=OpencorporaTag('ADJF,Qual masc,sing,nomn'), normal_form='неотмирный', score=0.14332603938730848, methods_stack=((DictionaryAnalyzer(), 'мирный', 87, 0), (UnknownPrefixAnalyzer(score_multiplier=0.5), 'т'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'нео')))\n"
     ]
    }
   ],
   "source": [
    "unworldy = MORPH.parse('неотмирный')[0]\n",
    "print(unworldy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69ab898a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'неотмирнее'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unworldy.inflect({'COMP'}).word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677cf09",
   "metadata": {},
   "source": [
    "С \"неотмирным\" - удача."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be7e699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse(word='безумный', tag=OpencorporaTag('ADJF,Subx,Qual masc,sing,nomn'), normal_form='безумный', score=0.5, methods_stack=((DictionaryAnalyzer(), 'безумный', 405, 0),))\n"
     ]
    }
   ],
   "source": [
    "insane = MORPH.parse('безумный')[0]\n",
    "print(insane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "867b9f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'безумнее'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insane.inflect({'COMP'}).word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb3f261",
   "metadata": {},
   "source": [
    "Гипотеза верна: нам не нужно задавать все граммемы присущие нужной форме данного слова, чтобы получить её. Достаточно\n",
    "ключевых признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3565a65",
   "metadata": {},
   "source": [
    "Проверим, что вернёт метод inflect, когда мы попытаемся получить с помощью него несуществующую форму слова. Например, \n",
    "краткое прилагательное соответствующее слову \"неземной\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ecd8cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse(word='неотмирный', tag=OpencorporaTag('ADJF,Qual masc,sing,nomn'), normal_form='неотмирный', score=0.14332603938730848, methods_stack=((DictionaryAnalyzer(), 'мирный', 87, 0), (UnknownPrefixAnalyzer(score_multiplier=0.5), 'т'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'нео')))\n"
     ]
    }
   ],
   "source": [
    "unearthly = MORPH.parse('неземной')[0]\n",
    "print(unearthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b88e2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unearthly_short = unearthly.inflect({'ADJS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c26d712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(unearthly_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cbf838",
   "metadata": {},
   "source": [
    "# Наречия и необходимость анализа предложений по составу\n",
    "в связи с тем, что pymorphy2 анализирует все слова изолированно существует неодназначность в определении частей речи: некоторые наречия могут быть определены им как прилагательные и наоборот. В текущей версии лермонтовизатора выбор делается в пользу прилагательных всегда, но это не совсем верно. Чтобы точно определять части речи слов, нужно определять какими членами предложения они являются. Начнём с простых предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4907ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"День немыслимо прекрасен\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07578d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 'день'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe05ce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unthinkable = 'немыслимо'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f75ff386",
   "metadata": {},
   "outputs": [],
   "source": [
    "lovely = 'прекрасен'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e7c498c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='день', tag=OpencorporaTag('NOUN,inan,masc sing,accs'), normal_form='день', score=0.745454, methods_stack=((DictionaryAnalyzer(), 'день', 1327, 3),)),\n",
       " Parse(word='день', tag=OpencorporaTag('NOUN,inan,masc sing,nomn'), normal_form='день', score=0.248484, methods_stack=((DictionaryAnalyzer(), 'день', 1327, 0),)),\n",
       " Parse(word='день', tag=OpencorporaTag('VERB,perf,tran sing,impr,excl'), normal_form='деть', score=0.00606, methods_stack=((DictionaryAnalyzer(), 'день', 684, 13),))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_obj = MORPH.parse(day)\n",
    "day_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c83ee",
   "metadata": {},
   "source": [
    "Слово \"день\" может быть либо существительным, либо глаголом второго лица повелительного наклонения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66121524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='немыслимо', tag=OpencorporaTag('ADVB'), normal_form='немыслимо', score=0.666666, methods_stack=((DictionaryAnalyzer(), 'немыслимо', 3, 0),)),\n",
       " Parse(word='немыслимо', tag=OpencorporaTag('ADJS,Qual neut,sing'), normal_form='немыслимый', score=0.333333, methods_stack=((DictionaryAnalyzer(), 'немыслимо', 2176, 29),))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unthinkable_obj = MORPH.parse(unthinkable)\n",
    "unthinkable_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e69bb",
   "metadata": {},
   "source": [
    "\"Немыслимо\" - именно тот случай когда по самому слову вне контекста нельзя сказать прилагательное это или наречие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42004a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='прекрасен', tag=OpencorporaTag('ADJS,Qual masc,sing'), normal_form='прекрасный', score=1.0, methods_stack=((DictionaryAnalyzer(), 'прекрасен', 223, 54),))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely_obj = MORPH.parse(lovely)\n",
    "lovely_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f42d9c8",
   "metadata": {},
   "source": [
    "\"прекрасен\" - однозначно прилагательное единственного числа мужского рода в иминительном падеже. Оно и должно быть отправной точкой в определении членов предложения. Оно должно относится к существительному так же единственного числа мужского рода в иминительном падеже.\n",
    "\n",
    "Но нужно ли нам определять все слова по их роли в предложении? Нам нужно лишь устранить неоднозначность в определении части речи слова \"немыслимо\". Если это прилагательное то оно должно относиться к существительному среднего рода единственного чила (например, \"небо немыслимо\"), но в этом предложении нет слов, которые могут быть существительными среднего рода единственного числа, значит, это не прилагательное.\n",
    "\n",
    "Кстати, неоднозначность у нас только с прилагательными среднего рода, т.к. прилагательные мужского, женского рода и множественного числа вне контекста не могут быть спутаны с наречием.\n",
    "\n",
    "\"Светло\" и небо, и просто светло. \"Ясно\" и понятно, и солнце. Ясный и светлая - это однозначно прилагательные. Проверим ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e790d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='светло', tag=OpencorporaTag('ADVB,Prdx'), normal_form='светло', score=0.5, methods_stack=((DictionaryAnalyzer(), 'светло', 404, 0),)),\n",
       " Parse(word='светло', tag=OpencorporaTag('ADJS,Qual neut,sing'), normal_form='светлый', score=0.5, methods_stack=((DictionaryAnalyzer(), 'светло', 2845, 56),))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bright = \"светло\"\n",
    "bright_obj = MORPH.parse(\"светло\")\n",
    "bright_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f58ec61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='ясно', tag=OpencorporaTag('ADVB,Prdx'), normal_form='ясно', score=0.916666, methods_stack=((DictionaryAnalyzer(), 'ясно', 404, 0),)),\n",
       " Parse(word='ясно', tag=OpencorporaTag('ADJS,Qual neut,sing'), normal_form='ясный', score=0.083333, methods_stack=((DictionaryAnalyzer(), 'ясно', 87, 56),))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear = \"ясно\"\n",
    "clear_obj = MORPH.parse(\"ясно\")\n",
    "clear_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deee7487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='светлый', tag=OpencorporaTag('ADJF,Qual masc,sing,nomn'), normal_form='светлый', score=0.5, methods_stack=((DictionaryAnalyzer(), 'светлый', 2845, 0),)),\n",
       " Parse(word='светлый', tag=OpencorporaTag('ADJF,Qual inan,masc,sing,accs'), normal_form='светлый', score=0.5, methods_stack=((DictionaryAnalyzer(), 'светлый', 2845, 4),))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bright_m = \"светлый\"\n",
    "bright_m_obj = MORPH.parse(\"светлый\")\n",
    "bright_m_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2433064",
   "metadata": {},
   "source": [
    "Здесь неоднозначность лишь в падеже прилагательного."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0434517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='ясная', tag=OpencorporaTag('ADJF,Qual femn,sing,nomn'), normal_form='ясный', score=1.0, methods_stack=((DictionaryAnalyzer(), 'ясная', 87, 7),))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_f = \"ясная\"\n",
    "clear_f_obj = MORPH.parse(\"ясная\")\n",
    "clear_f_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae41532",
   "metadata": {},
   "source": [
    "Здесь всё однозначно:  прилагательное (качественное - что для нашей задачи не важно) женского рода единственного числа\n",
    "в иминительном падеже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0dd6e7",
   "metadata": {},
   "source": [
    "Рассмотрим вариант использования наречия и краткого прилагательного среднего рода единственного числа в именительном падеже \n",
    "в предложении."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0c065",
   "metadata": {},
   "source": [
    "1.\n",
    "День немыслимо прекрасен.\n",
    "Немыслимы день прекрасен.\n",
    "День прекрасен немыслимо.\n",
    "Прекрасен немыслимо день.\n",
    "\n",
    "В таком предложении можно определить часть речи слова \"немыслимо\" просто по тому, что в нём нет существительного среднего рода."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec31b85",
   "metadata": {},
   "source": [
    "2. День немыслимо прекрасен, небо чисто и светло."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae17c3",
   "metadata": {},
   "source": [
    "Допустим, небо здесь не только чисто и светло, но и немыслимо. Но прилагательные относящиеся к разным существительным не перемешиваются."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d21690",
   "metadata": {},
   "source": [
    "Т.е. предложение в этом случае должно было бы строиться так: День прекрасен, немыслимо небо, чисто и светло."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e952e195",
   "metadata": {},
   "source": [
    "Между прилагательным и существительным быть вводное слово или сравнительный оборот.\n",
    "Светло как никогда небо.\n",
    "Светло как солнце небо.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4202785f",
   "metadata": {},
   "source": [
    "Синтаксический анализ русского языка\n",
    "https://habr.com/ru/post/464959/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a918b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: git@github.com:allyotov/syntax_analyzer.git#egg=syntax_analyzer is not a valid editable requirement. It should either be a path to a local project or a VCS URL (beginning with bzr+http, bzr+https, bzr+ssh, bzr+sftp, bzr+ftp, bzr+lp, bzr+file, git+http, git+https, git+ssh, git+git, git+file, hg+file, hg+http, hg+https, hg+ssh, hg+static-http, svn+ssh, svn+http, svn+https, svn+svn, svn+file).\n"
     ]
    }
   ],
   "source": [
    "!pip install -e \"git@github.com:allyotov/syntax_analyzer.git#egg=syntax_analyzer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42511bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining syntax_analyzer from git+https://github.com/allyotov/syntax_analyzer.git#egg=syntax_analyzer\n",
      "  Cloning https://github.com/allyotov/syntax_analyzer.git to d:\\practice\\personal_projects\\lermontovization-0.25\\preprod_research\\src\\syntax-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/allyotov/syntax_analyzer.git 'D:\\practice\\personal_projects\\Lermontovization-0.25\\preprod_research\\src\\syntax-analyzer'\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'D:\\anaconda3\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'D:\\\\practice\\\\personal_projects\\\\Lermontovization-0.25\\\\preprod_research\\\\src\\\\syntax-analyzer\\\\setup.py'\"'\"'; __file__='\"'\"'D:\\\\practice\\\\personal_projects\\\\Lermontovization-0.25\\\\preprod_research\\\\src\\\\syntax-analyzer\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\Al\\AppData\\Local\\Temp\\pip-pip-egg-info-prcre9ka'\n",
      "         cwd: D:\\practice\\personal_projects\\Lermontovization-0.25\\preprod_research\\src\\syntax-analyzer\\\n",
      "    Complete output (5 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"D:\\anaconda3\\lib\\tokenize.py\", line 392, in open\n",
      "        buffer = _builtin_open(filename, 'rb')\n",
      "    FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\practice\\\\personal_projects\\\\Lermontovization-0.25\\\\preprod_research\\\\src\\\\syntax-analyzer\\\\setup.py'\n",
      "    ----------------------------------------\n",
      "WARNING: Discarding git+https://github.com/allyotov/syntax_analyzer.git#egg=syntax_analyzer. Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n",
      "ERROR: Could not find a version that satisfies the requirement syntax-analyzer (unavailable)\n",
      "ERROR: No matching distribution found for syntax-analyzer (unavailable)\n"
     ]
    }
   ],
   "source": [
    "!pip install -e \"git+https://github.com/allyotov/syntax_analyzer.git#egg=syntax_analyzer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f56f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting syntax_analyzer\n",
      "  Cloning https://github.com/allyotov/syntax_analyzer.git to c:\\users\\al\\appdata\\local\\temp\\pip-install-f9fwj6am\\syntax-analyzer_8f0812d815a54a7488a9f57909309bde\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/allyotov/syntax_analyzer.git 'C:\\Users\\Al\\AppData\\Local\\Temp\\pip-install-f9fwj6am\\syntax-analyzer_8f0812d815a54a7488a9f57909309bde'\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'D:\\anaconda3\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Al\\\\AppData\\\\Local\\\\Temp\\\\pip-install-f9fwj6am\\\\syntax-analyzer_8f0812d815a54a7488a9f57909309bde\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Al\\\\AppData\\\\Local\\\\Temp\\\\pip-install-f9fwj6am\\\\syntax-analyzer_8f0812d815a54a7488a9f57909309bde\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\Al\\AppData\\Local\\Temp\\pip-pip-egg-info-2vcbqqyh'\n",
      "         cwd: C:\\Users\\Al\\AppData\\Local\\Temp\\pip-install-f9fwj6am\\syntax-analyzer_8f0812d815a54a7488a9f57909309bde\\\n",
      "    Complete output (5 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"D:\\anaconda3\\lib\\tokenize.py\", line 392, in open\n",
      "        buffer = _builtin_open(filename, 'rb')\n",
      "    FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Al\\\\AppData\\\\Local\\\\Temp\\\\pip-install-f9fwj6am\\\\syntax-analyzer_8f0812d815a54a7488a9f57909309bde\\\\setup.py'\n",
      "    ----------------------------------------\n",
      "WARNING: Discarding git+https://github.com/allyotov/syntax_analyzer.git#egg=syntax_analyzer. Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n",
      "ERROR: Could not find a version that satisfies the requirement syntax-analyzer (unavailable)\n",
      "ERROR: No matching distribution found for syntax-analyzer (unavailable)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"git+https://github.com/allyotov/syntax_analyzer.git#egg=syntax_analyzer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a748600f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting syntax_analyzer\n",
      "  Cloning https://github.com/allyotov/syntax_analyzer.git to c:\\users\\al\\appdata\\local\\temp\\pip-install-w8kyvcwp\\syntax-analyzer_1b5f3a77161748578390749be56e60ce\n",
      "Building wheels for collected packages: syntax-analyzer\n",
      "  Building wheel for syntax-analyzer (setup.py): started\n",
      "  Building wheel for syntax-analyzer (setup.py): finished with status 'done'\n",
      "  Created wheel for syntax-analyzer: filename=syntax_analyzer-0.0.0-py3-none-any.whl size=5958 sha256=c99c941ae757b5f2f107d5a1ddf5b5993fa4e2462bd6c757117ceb561531fd43\n",
      "  Stored in directory: C:\\Users\\Al\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-8zhdhx4g\\wheels\\68\\cc\\d8\\59509ea110a7bac37662aca8e84ddabcd6637b5d53eb5c1724\n",
      "Successfully built syntax-analyzer\n",
      "Installing collected packages: syntax-analyzer\n",
      "Successfully installed syntax-analyzer-0.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/allyotov/syntax_analyzer.git 'C:\\Users\\Al\\AppData\\Local\\Temp\\pip-install-w8kyvcwp\\syntax-analyzer_1b5f3a77161748578390749be56e60ce'\n"
     ]
    }
   ],
   "source": [
    "!pip install \"git+https://github.com/allyotov/syntax_analyzer.git#egg=syntax_analyzer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "174fd5db",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-9e982e29cd71>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-8-9e982e29cd71>\"\u001B[1;36m, line \u001B[1;32m1\u001B[0m\n\u001B[1;33m    from syntax_analyzer-0.0.0.dist-info import analyzer\u001B[0m\n\u001B[1;37m                        ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from syntax_analyzer-0.0.0.dist-info import analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67885c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting syntax_analyzer\n",
      "  Cloning https://github.com/allyotov/syntax_analyzer.git to c:\\users\\al\\appdata\\local\\temp\\pip-install-yj1p174a\\syntax-analyzer_3b3d2062dfff40209a477135d1a2b104\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Building wheels for collected packages: syntax-analyzer\n",
      "  Building wheel for syntax-analyzer (PEP 517): started\n",
      "  Building wheel for syntax-analyzer (PEP 517): finished with status 'done'\n",
      "  Created wheel for syntax-analyzer: filename=syntax_analyzer-0.0.1-py3-none-any.whl size=7113 sha256=e81aa08b449d595419dcc1764cc5a0c7354f967330105ded23d1046cdcbdb69e\n",
      "  Stored in directory: C:\\Users\\Al\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-rx7y1k5h\\wheels\\68\\cc\\d8\\59509ea110a7bac37662aca8e84ddabcd6637b5d53eb5c1724\n",
      "Successfully built syntax-analyzer\n",
      "Installing collected packages: syntax-analyzer\n",
      "  Attempting uninstall: syntax-analyzer\n",
      "    Found existing installation: syntax-analyzer 0.0.0\n",
      "    Uninstalling syntax-analyzer-0.0.0:\n",
      "      Successfully uninstalled syntax-analyzer-0.0.0\n",
      "Successfully installed syntax-analyzer-0.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/allyotov/syntax_analyzer.git 'C:\\Users\\Al\\AppData\\Local\\Temp\\pip-install-yj1p174a\\syntax-analyzer_3b3d2062dfff40209a477135d1a2b104'\n"
     ]
    }
   ],
   "source": [
    "!pip install \"git+https://github.com/allyotov/syntax_analyzer.git#egg=syntax_analyzer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85306d90",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'parse_tree'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-37c29509e93f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0msyntax_analyzer\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0manalyzer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\anaconda3\\lib\\site-packages\\syntax_analyzer\\analyzer.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mshelve\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mitertools\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mparse_tree\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mparse_tree\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mTree\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mRoot\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mNode\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'parse_tree'"
     ]
    }
   ],
   "source": [
    "from syntax_analyzer import analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc3fd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting syntax_analyzer\n",
      "  Cloning https://github.com/allyotov/syntax_analyzer.git to c:\\users\\al\\appdata\\local\\temp\\pip-install-qiciqh9y\\syntax-analyzer_cf4fe7be60104db5a08cdbc2c4ef5cae\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/allyotov/syntax_analyzer.git 'C:\\Users\\Al\\AppData\\Local\\Temp\\pip-install-qiciqh9y\\syntax-analyzer_cf4fe7be60104db5a08cdbc2c4ef5cae'\n"
     ]
    }
   ],
   "source": [
    "!pip install \"git+https://github.com/allyotov/syntax_analyzer.git#egg=syntax_analyzer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aae9443b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'parse_tree'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-37c29509e93f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0msyntax_analyzer\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0manalyzer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\anaconda3\\lib\\site-packages\\syntax_analyzer\\analyzer.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mshelve\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mitertools\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mparse_tree\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mparse_tree\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mTree\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mRoot\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mNode\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'parse_tree'"
     ]
    }
   ],
   "source": [
    "from syntax_analyzer import analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad89f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting syntax_analyzer\n",
      "  Cloning https://github.com/allyotov/syntax_analyzer.git to c:\\users\\al\\appdata\\local\\temp\\pip-install-s73ggvk2\\syntax-analyzer_51fb0732bc85486f92517e182e6b3c4c\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/allyotov/syntax_analyzer.git 'C:\\Users\\Al\\AppData\\Local\\Temp\\pip-install-s73ggvk2\\syntax-analyzer_51fb0732bc85486f92517e182e6b3c4c'\n"
     ]
    }
   ],
   "source": [
    "!pip install \"git+https://github.com/allyotov/syntax_analyzer.git#egg=syntax_analyzer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af0bd9b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'parse_tree'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-14-37c29509e93f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0msyntax_analyzer\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0manalyzer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\anaconda3\\lib\\site-packages\\syntax_analyzer\\analyzer.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mshelve\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mitertools\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mparse_tree\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mparse_tree\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mTree\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mRoot\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mNode\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'parse_tree'"
     ]
    }
   ],
   "source": [
    "from syntax_analyzer import analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de302bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall syntax_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d06589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}